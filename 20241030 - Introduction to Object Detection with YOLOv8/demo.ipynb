{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Object Detection with YOLOv8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Outline\n",
    "1. Setting up dependencies and libraries\n",
    "2. Loading and demo on pre-trained model\n",
    "3. Dataset Contents\n",
    "4. Training a model from scratch\n",
    "5. Evaluation and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies and Libraries\n",
    "The following is the list of libraries you need to install:\n",
    "- Python (version >= 3.8)\n",
    "- [PyTorch (CUDA version / CPU-Only)](https://pytorch.org/get-started/locally/)\n",
    "    - Torchvision\n",
    "    - Torchaudio\n",
    "- [CUDA](https://developer.nvidia.com/cuda-toolkit-archive)\n",
    "    - [Checking GPU compatibility](https://developer.nvidia.com/cuda-gpus)\n",
    "- [Ultralytics](https://docs.ultralytics.com/quickstart/)\n",
    "    - Alternative (For Development Version): [Github Repo](https://github.com/ultralytics/ultralytics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "\n",
    "# For Visualizations\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Trained Model\n",
    "- [List of available models](https://docs.ultralytics.com/models/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a model\n",
    "model = YOLO(model=\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Sample Original Image\n",
    "img = cv2.imread(\"sample1.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(\"Original\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform prediction on two images\n",
    "results = model.predict([\"sample1.jpg\",\"sample2.jpg\"],\n",
    "                       save=True,\n",
    "                       exist_ok=True,\n",
    "                       project=\"predict\",\n",
    "                       name=\"demo\",\n",
    "                       verbose=False)\n",
    "\n",
    "# View contents of results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detections of the first image\n",
    "boxes = results[0].boxes\n",
    "img_det = img.copy()\n",
    "\n",
    "for box in boxes:\n",
    "    x1, y1, x2, y2 = box.xyxy[0]\n",
    "    label = results[0].names[int(box.cls[0])]\n",
    "\n",
    "    # Drawing of Bounding Boxes and Labels\n",
    "    cv2.rectangle(img_det, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 255), 2)\n",
    "    cv2.putText(img_det, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_det)\n",
    "plt.axis('off')\n",
    "plt.title(\"Image w/ Detections\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization automatically generated by Ultralytics\n",
    "img_det = cv2.imread(os.path.join('predict', \n",
    "                                  'demo',\n",
    "                                  'sample1.jpg'))\n",
    "img_det = cv2.cvtColor(img_det, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img_det)\n",
    "plt.axis('off')\n",
    "plt.title(\"Image w/ Detections\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Dataset\n",
    "- For the datasets used in this workshop, you can download them here: [datasets.zip](https://drive.google.com/file/d/1z5usegJoqEK7GZET4W9dudU2nszbjluA/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ultralytics Datasets\n",
    "- [List of available datasets](https://docs.ultralytics.com/datasets/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Use (This will download the dataset)\n",
    "# model.train(data=\"coco8.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Folder Structure of Custom Dataset\n",
    "def list_files(startpath):\n",
    "    for root, _, files in os.walk(startpath):\n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        dash = '-' * (level + 1)\n",
    "        print('{}{}'.format(dash, os.path.basename(root)))\n",
    "        for f in files[:1]:\n",
    "            print('{}{}'.format(dash + '-', f))\n",
    "\n",
    "list_files(\"datasets/african-wildlife\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Label File\n",
    "with open(\"datasets/african-wildlife/train/labels/1 (43).txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "print(\"Sample Annotations: \\n\")\n",
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample .yaml file\n",
    "with open(\"datasets/african-wildlife/data.yaml\", \"r\") as file:\n",
    "    lines = [line.strip() for line in file.readlines()]\n",
    "    \n",
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLOv8 Model From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading of Model without Pre-Trained Weights\n",
    "model = YOLO(model=\"yolov8n.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Function\n",
    "metrics = model.train(data=os.path.join(\"datasets\", # Dataset to be Trained\n",
    "                                        \"african-wildlife\",\n",
    "                                        \"data.yaml\"), \n",
    "                                        \n",
    "                      val=False, # Performing Validation Every Epoch\n",
    "\n",
    "                      cache=True, # Cache on True/`ram`, `disk` or False\n",
    "                      device=0, # Available for multi-GPUs (eg. 0,1) or Apple chips (mps)\n",
    "                        \n",
    "                      #--- HYPERPARAMETERS ---#\n",
    "                      epochs=5, # Training epochs\n",
    "                      batch=32, # Batch size, auto mode if set to decimal \n",
    "\n",
    "                      optimizer=\"Adam\", # has auto option\n",
    "                      lr0=0.001, # initial learning rate\n",
    "                      lrf=0.01, # final learning rate = lr0 * lrf\n",
    "                      momentum=0.9, # momentum factor\n",
    "                      \n",
    "\n",
    "                      #--- SAMPLE AUGMENTATIONS ---#\n",
    "                      imgsz=640, # Resizes Images\n",
    "                      translate=0.1, # Moves the image a fraction of the image size\n",
    "                      scale=0.5, # Scales image by a factor\n",
    "                      mosaic=1.0, # Combines 4 training images into one\n",
    "                      mixup=1.0, # Blends two images and their labels\n",
    "                      \n",
    "                        \n",
    "                      #--- SAVING ---#\n",
    "                      save=True, \n",
    "                      save_period=1, # checkpoint saves\n",
    "\n",
    "                      seed=123, # Reproduce Results\n",
    "                      exist_ok=True,\n",
    "                      project=\"train\", # Training Directory\n",
    "                      name=\"yolov8n_wildlife\", # Save Folder Name\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Custom Training/Testing Loop\n",
    "model.model.train()\n",
    "model.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resuming Training from Last Save\n",
    "model = YOLO(os.path.join(\"train\",\n",
    "                          \"yolov8n_wildlife\",\n",
    "                          \"weights\",\n",
    "                          \"last.pt\"))\n",
    "results = model.train(resume=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading best model from training\n",
    "model = YOLO(os.path.join(\"train\",\n",
    "                          \"yolov8n_wildlife\",\n",
    "                          \"weights\",\n",
    "                          \"best.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Evaluation\n",
    "metrics = model.val(data=os.path.join(\"datasets\",\n",
    "                                      \"african-wildlife\",\n",
    "                                      \"data.yaml\"),\n",
    "                    split=\"test\",\n",
    "                    batch=32,\n",
    "                    conf=0.001, # Score Threshold\n",
    "                    iou=0.6, # IoU threshold for NMS\n",
    "                    max_det=300, # Maximum number of detections\n",
    "                    exist_ok=True,\n",
    "                    project=\"eval\",\n",
    "                    name=\"yolov8n_wildlife\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Scores From Metrics Object\n",
    "print('mAP50-95:', metrics.box.map)\n",
    "print('mAP50:', metrics.box.map50)\n",
    "print('mAP75:', metrics.box.map75)\n",
    "print('mAP50-95 per class:', metrics.box.maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Generated\n",
    "img = cv2.imread(os.path.join(\"eval\",\n",
    "                              \"yolov8n_wildlife\",\n",
    "                              \"confusion_matrix.png\"))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(\"Original\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading best model from training\n",
    "model = YOLO(os.path.join(\"train\",\n",
    "                          \"yolov8n_wildlife\",\n",
    "                          \"weights\",\n",
    "                          \"best.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Detections\n",
    "results = model.predict(source=os.path.join(\"datasets\",\n",
    "                                      \"african-wildlife\",\n",
    "                                      \"test\",\n",
    "                                      \"images\"),\n",
    "                        conf=0.1, # Score Threshold\n",
    "                        iou=0.5, # IoU threshold for NMS\n",
    "                        max_det=300, # Maximum number of detections\n",
    "                        save_txt=True, # Bounding box predictions and labels\n",
    "                        save=True, # Visualization\n",
    "                        verbose=False,\n",
    "                        exist_ok=True,\n",
    "                        project=\"predict\",\n",
    "                        name=\"yolov8n_wildlife\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rnd\n",
    "\n",
    "# Get detections of a random image\n",
    "index = 4 # rnd.randint(0, len(results))\n",
    "img = cv2.imread(results[index].path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "boxes = results[index].boxes\n",
    "\n",
    "for box in boxes:\n",
    "    x1, y1, x2, y2 = box.xyxy[0]\n",
    "    label = results[0].names[int(box.cls[0])]\n",
    "    \n",
    "    # Drawing of Bounding Boxes and Labels\n",
    "    cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 255), 2)\n",
    "    cv2.putText(img, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(\"Image w/ Detections\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization automatically generated by Ultralytics\n",
    "predict_dir = os.listdir(os.path.join('predict', 'yolov8n_wildlife'))\n",
    "\n",
    "img_det = cv2.imread(os.path.join('predict', 'yolov8n_wildlife', predict_dir[index]))\n",
    "img_det = cv2.cvtColor(img_det, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img_det)\n",
    "plt.axis('off')\n",
    "plt.title(\"Image w/ Detections\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful References\n",
    "- [PyTorch and Virtual Environment Setup](https://www.youtube.com/watch?v=GMSjDTU8Zlc)\n",
    "- [List of YOLO Train Settings](https://docs.ultralytics.com/modes/train/#train-settings)\n",
    "- [List of YOLO Val Settings](https://docs.ultralytics.com/modes/val/#arguments-for-yolo-model-validation)\n",
    "- [List of YOLO Predict Settings](https://docs.ultralytics.com/modes/predict/#inference-arguments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
